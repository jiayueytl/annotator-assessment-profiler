{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6d2b5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "174600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_key = pd.read_csv(r'annotator-assessment-profiler\\answer\\answer_key.csv')\n",
    "responses = pd.read_csv(r'C:\\Users\\jiayue.tan\\Downloads\\YTL AI Labs Annotator Application & Assessment(Applicants) (1).csv',header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d48a216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new, single-level list of column names by joining the two levels\n",
    "# Example: ('Malay Q1 (Prompt)', 'Evaluate whether...') -> 'Malay Q1 (Prompt) | Evaluate whether...'\n",
    "responses.columns = [' | '.join(col).strip() for col in responses.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "95f0c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = responses.columns.tolist()\n",
    "prefixes = (\"Malay\", \"English\", \"Chinese\")\n",
    "\n",
    "# 3. Use list comprehension to filter the columns\n",
    "language_columns = [\n",
    "    col for col in all_columns\n",
    "    if col.startswith(prefixes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "874ea112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Generated Column Rename Map ###\n",
      "column_map = {\n",
      "    \"Malay Q1 (Prompt) | Evaluate whether the prompt in the image above OR in the bolded blue text below is usable.\": \"malay_q1_prompt_status\",\n",
      "    \"Malay Q1 (Response) | Evaluate the quality of the response in the image above OR in the bolded blue text below.\": \"malay_q1_response_status\",\n",
      "    \"Malay Q2 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.\": \"malay_q2_prompt_status\",\n",
      "    \"Malay Q2 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below.\": \"malay_q2_response_status\",\n",
      "    \"Malay Q3 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.\": \"malay_q3_prompt_status\",\n",
      "    \"Malay Q3 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below\": \"malay_q3_response_status\",\n",
      "    \"Malay Q4 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.1\": \"malay_q4_prompt_status\",\n",
      "    \"Malay Q4 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below.1\": \"malay_q4_response_status\",\n",
      "    \"Malay Q5 (prompt)  | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.2\": \"malay_q5_prompt_status\",\n",
      "    \"Malay Q5 (response)  | Evaluate the quality of the response written in the image above OR in the bolded blue text below1\": \"malay_q5_response_status\",\n",
      "    \"English Q1 (Prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.3\": \"english_q1_prompt_status\",\n",
      "    \"English Q1 (Response | Evaluate the quality of the response written in the image above OR in the bolded blue text below.2\": \"english_q1_response_status\",\n",
      "    \"English Q2 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.4\": \"english_q2_prompt_status\",\n",
      "    \"English Q2 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below.3\": \"english_q2_response_status\",\n",
      "    \"English Q3 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.5\": \"english_q3_prompt_status\",\n",
      "    \"English Q3 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below.4\": \"english_q3_response_status\",\n",
      "    \"English Q4 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.6\": \"english_q4_prompt_status\",\n",
      "    \"English Q4 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below.5\": \"english_q4_response_status\",\n",
      "    \"English Q5 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below) is usable.\": \"english_q5_prompt_status\",\n",
      "    \"English Q5 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below.6\": \"english_q5_response_status\",\n",
      "    \"Chinese Q1 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.7\": \"chinese_q1_prompt_status\",\n",
      "    \"Chinese Q1 (response) | Evaluate the quality of the response written in the image above OR in the bolded blue text below.7\": \"chinese_q1_response_status\",\n",
      "    \"Chinese Q2 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.8\": \"chinese_q2_prompt_status\",\n",
      "    \"Chinese Q2 (response) | Evaluate the quality of the response written in the image above or in the bolded blue text below.8\": \"chinese_q2_response_status\",\n",
      "    \"Chinese Q3 (prompt) | Evaluate whether the prompt written in the image above OR in the bolded blue text below is usable.9\": \"chinese_q3_prompt_status\",\n",
      "    \"Chinese Q3 (response) | Evaluate the quality of the response written in the image above or in the bolded blue text below.9\": \"chinese_q3_response_status\",\n",
      "    \"Chinese Q4 (prompt) | Evaluate whether the prompt (written in the image above or in the bolded blue text below) is usable.\": \"chinese_q4_prompt_status\",\n",
      "    \"Chinese Q4 (response) | Evaluate the quality of the response written in the image above or in the bolded blue text below.10\": \"chinese_q4_response_status\",\n",
      "    \"Chinese Q5 (prompt) | Evaluate whether the prompt (written in the image above or in the bolded blue text below) is usable.1\": \"chinese_q5_prompt_status\",\n",
      "    \"Chinese Q5 (response) | Evaluate the quality of the response written in the image above or in the bolded blue text below.11\": \"chinese_q5_response_status\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the full text patterns you want to hard-rename\n",
    "PROMPT_STATUS_PATTERN = \"evaluate whether the prompt.*is usable.*\"\n",
    "RESPONSE_STATUS_PATTERN = \"evaluate the quality of the response.*in the bolded blue text below.*\"\n",
    "\n",
    "# The dictionary to store the final mapping\n",
    "column_map = {}\n",
    "\n",
    "for old_col in responses.columns:\n",
    "    # 1. Lowercase the entire column for consistent matching\n",
    "    lower_col = old_col.lower().strip()\n",
    "\n",
    "    # 2. Split the column into the prefix and the evaluation question\n",
    "    # Example: 'malay q1 (prompt) | evaluate...'\n",
    "    parts = lower_col.split(' | ', 1)\n",
    "    if len(parts) < 2:\n",
    "        # Skip columns that don't match the expected MultiIndex format\n",
    "        continue\n",
    "\n",
    "    prefix, question = parts[0], parts[1]\n",
    "\n",
    "    # Clean up the prefix: 'malay q1 (prompt)' -> 'malay_q1_prompt'\n",
    "    # Use re.sub to remove non-alphanumeric/non-space characters, then replace spaces with underscores\n",
    "    cleaned_prefix = re.sub(r'[^a-z0-9\\s]', '', prefix).replace(' ', '_').strip('_')\n",
    "    \n",
    "    # 3. Apply the mapping logic to determine the suffix\n",
    "    new_suffix = None\n",
    "    if re.search(PROMPT_STATUS_PATTERN, question):\n",
    "        new_suffix = \"status\"\n",
    "    elif re.search(RESPONSE_STATUS_PATTERN, question):\n",
    "        new_suffix = \"status\"\n",
    "    \n",
    "    # If a new suffix was found, construct the new column name\n",
    "    if new_suffix:\n",
    "        new_col_name = f\"{cleaned_prefix}_{new_suffix}\"\n",
    "        \n",
    "        # 4. Add the original column (case-sensitive) and the new name to the map\n",
    "        column_map[old_col] = new_col_name\n",
    "    \n",
    "# Print the final mapping dictionary\n",
    "print(\"### Generated Column Rename Map ###\")\n",
    "print(\"column_map = {\")\n",
    "for old, new in column_map.items():\n",
    "    print(f'    \"{old}\": \"{new}\",')\n",
    "print(\"}\")\n",
    "\n",
    "# Now you can apply this to your DataFrame:\n",
    "responses.rename(columns=column_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "cbb7d876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   malay_confidence  english_confidence  chinese_confidence\n",
      "0                 1                   1                   0\n",
      "1                 1                   1                   1\n",
      "2                 1                   1                   1\n",
      "3                 1                   1                   1\n",
      "4                 1                   1                   1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 203 entries, 0 to 202\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   malay_confidence    203 non-null    int64\n",
      " 1   english_confidence  203 non-null    int64\n",
      " 2   chinese_confidence  203 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 4.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Define the specific hard rename map for the CONFIDENCE_COLUMNS\n",
    "CONFIDENT_LANGUAGE_MAP = {\n",
    "    'Unnamed: 15_level_0 | This question is about Bahasa Melayu (BM) language abilities.\\nAre you confident reviewing and writing in both everyday/casual language (e.g. social media posts, chat messages) and more formal language': 'malay_confidence',\n",
    "    'Unnamed: 16_level_0 | This question is about English language abilities.\\nAre you confident reviewing and writing in both everyday/casual language (e.g. social media posts, chat messages) and more formal language (e.g. news': 'english_confidence',\n",
    "    'Unnamed: 17_level_0 | This question is about Mandarin Chinese language abilities.\\nAre you comfortable reviewing and writing in both everyday/casual language (e.g. social media posts, chat messages) and more formal language': 'chinese_confidence'\n",
    "}\n",
    "\n",
    "# 2. Define the function for value encoding\n",
    "def encode_confidence(value):\n",
    "    \"\"\"Encodes the string value to 0 if 'no' is present, or 1 otherwise.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    # Convert to string and check if 'no' is in the lowercased value\n",
    "    if 'no' in str(value).lower():\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "# 3. Define the main function to load, rename, and process the data\n",
    "def process_confidence_columns(df):\n",
    "\n",
    "    df.rename(columns=CONFIDENT_LANGUAGE_MAP, inplace=True)\n",
    "\n",
    "    new_confidence_cols = list(CONFIDENT_LANGUAGE_MAP.values())\n",
    "\n",
    "    for col in new_confidence_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(encode_confidence)\n",
    "\n",
    "    print(df[new_confidence_cols].head())\n",
    "    print(df[new_confidence_cols].info())\n",
    "    \n",
    "    return df\n",
    "\n",
    "responses2 = process_confidence_columns(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6bc3428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLUMNS_MAP = {'Unnamed: 6_level_0 | Full name (according to NRIC):':\"name\",\n",
    "                  'Unnamed: 9_level_0 | IC number:':\"ic_number\"}\n",
    "\n",
    "responses2.rename(columns=ID_COLUMNS_MAP,inplace=True)\n",
    "\n",
    "responses2.head(2)\n",
    "\n",
    "responses3 = responses2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1ff7953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ic_number</th>\n",
       "      <th>name</th>\n",
       "      <th>malay_confidence</th>\n",
       "      <th>english_confidence</th>\n",
       "      <th>chinese_confidence</th>\n",
       "      <th>malay_q1_prompt_status</th>\n",
       "      <th>malay_q1_response_status</th>\n",
       "      <th>malay_q2_prompt_status</th>\n",
       "      <th>malay_q2_response_status</th>\n",
       "      <th>malay_q3_prompt_status</th>\n",
       "      <th>...</th>\n",
       "      <th>chinese_q1_prompt_status</th>\n",
       "      <th>chinese_q1_response_status</th>\n",
       "      <th>chinese_q2_prompt_status</th>\n",
       "      <th>chinese_q2_response_status</th>\n",
       "      <th>chinese_q3_prompt_status</th>\n",
       "      <th>chinese_q3_response_status</th>\n",
       "      <th>chinese_q4_prompt_status</th>\n",
       "      <th>chinese_q4_response_status</th>\n",
       "      <th>chinese_q5_prompt_status</th>\n",
       "      <th>chinese_q5_response_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60511081143</td>\n",
       "      <td>Tang Eugine</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIL (Minor rewrite, ≤ 2 sentences)</td>\n",
       "      <td>PASS (no changes)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS (no changes)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50111080310</td>\n",
       "      <td>Tang Yvone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>FAIL (Major rewrite, &gt; 2 sentences)</td>\n",
       "      <td>PASS (no changes)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL (needs improvement)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>...</td>\n",
       "      <td>FAIL (Minor Rewrite, ≤ 2 sentences)</td>\n",
       "      <td>PASS (no changes)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL (needs improvement)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS (no changes)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL (needs improvement)</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS (no changes)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ic_number         name  malay_confidence  english_confidence  \\\n",
       "0  60511081143  Tang Eugine                 1                   1   \n",
       "1  50111080310   Tang Yvone                 1                   1   \n",
       "\n",
       "   chinese_confidence               malay_q1_prompt_status  \\\n",
       "0                   0  FAIL (Minor rewrite, ≤ 2 sentences)   \n",
       "1                   1  FAIL (Major rewrite, > 2 sentences)   \n",
       "\n",
       "  malay_q1_response_status malay_q2_prompt_status  malay_q2_response_status  \\\n",
       "0        PASS (no changes)                   PASS         PASS (no changes)   \n",
       "1        PASS (no changes)                   PASS  FAIL (needs improvement)   \n",
       "\n",
       "  malay_q3_prompt_status  ...             chinese_q1_prompt_status  \\\n",
       "0                   PASS  ...                                  NaN   \n",
       "1                   PASS  ...  FAIL (Minor Rewrite, ≤ 2 sentences)   \n",
       "\n",
       "  chinese_q1_response_status chinese_q2_prompt_status  \\\n",
       "0                        NaN                      NaN   \n",
       "1          PASS (no changes)                     PASS   \n",
       "\n",
       "  chinese_q2_response_status chinese_q3_prompt_status  \\\n",
       "0                        NaN                      NaN   \n",
       "1   FAIL (needs improvement)                     PASS   \n",
       "\n",
       "  chinese_q3_response_status chinese_q4_prompt_status  \\\n",
       "0                        NaN                      NaN   \n",
       "1          PASS (no changes)                     PASS   \n",
       "\n",
       "  chinese_q4_response_status chinese_q5_prompt_status  \\\n",
       "0                        NaN                      NaN   \n",
       "1   FAIL (needs improvement)                     PASS   \n",
       "\n",
       "  chinese_q5_response_status  \n",
       "0                        NaN  \n",
       "1          PASS (no changes)  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renamed_scoring_columns = [\n",
    "    col for col in responses3.columns\n",
    "    if col.startswith((\"malay_\",\"chinese_\",\"english_\"))\n",
    "]\n",
    "\n",
    "scoring_columns = ['ic_number','name']+ renamed_scoring_columns\n",
    "responses3 = responses3[scoring_columns]\n",
    "responses3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "55f6e7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ic_number', 'name', 'malay_confidence', 'english_confidence',\n",
       "       'chinese_confidence', 'malay_q1_prompt_status',\n",
       "       'malay_q1_response_status', 'malay_q2_prompt_status',\n",
       "       'malay_q2_response_status', 'malay_q3_prompt_status',\n",
       "       'malay_q3_response_status', 'malay_q4_prompt_status',\n",
       "       'malay_q4_response_status', 'malay_q5_prompt_status',\n",
       "       'malay_q5_response_status', 'english_q1_prompt_status',\n",
       "       'english_q1_response_status', 'english_q2_prompt_status',\n",
       "       'english_q2_response_status', 'english_q3_prompt_status',\n",
       "       'english_q3_response_status', 'english_q4_prompt_status',\n",
       "       'english_q4_response_status', 'english_q5_prompt_status',\n",
       "       'english_q5_response_status', 'chinese_q1_prompt_status',\n",
       "       'chinese_q1_response_status', 'chinese_q2_prompt_status',\n",
       "       'chinese_q2_response_status', 'chinese_q3_prompt_status',\n",
       "       'chinese_q3_response_status', 'chinese_q4_prompt_status',\n",
       "       'chinese_q4_response_status', 'chinese_q5_prompt_status',\n",
       "       'chinese_q5_response_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1e01e26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ic_number</th>\n",
       "      <th>name</th>\n",
       "      <th>malay_confidence</th>\n",
       "      <th>english_confidence</th>\n",
       "      <th>chinese_confidence</th>\n",
       "      <th>malay_scores</th>\n",
       "      <th>english_scores</th>\n",
       "      <th>chinese_scores</th>\n",
       "      <th>malay_narrative</th>\n",
       "      <th>english_narrative</th>\n",
       "      <th>chinese_narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60511081143</td>\n",
       "      <td>Tang Eugine</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Total Score: 5.0 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 5.0 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 0.0 out of 10 questions. (All Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50111080310</td>\n",
       "      <td>Tang Yvone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Total Score: 7.0 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 6.0 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 7.0 out of 10 questions. Mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50625140990</td>\n",
       "      <td>KHONG YIROU</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Total Score: 6.5 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 5.5 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 6.5 out of 10 questions. Mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50609050370</td>\n",
       "      <td>SIA ZI YUE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Total Score: 7.0 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 8.0 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 5.0 out of 10 questions. Mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50211010344</td>\n",
       "      <td>OI KAY YI</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Total Score: 6.0 out of 10 questions. Mismatch...</td>\n",
       "      <td>Total Score: 9.0 out of 10 questions. (All Per...</td>\n",
       "      <td>Total Score: 7.5 out of 10 questions. Mismatch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ic_number         name  malay_confidence  english_confidence  \\\n",
       "0  60511081143  Tang Eugine                 1                   1   \n",
       "1  50111080310   Tang Yvone                 1                   1   \n",
       "2  50625140990  KHONG YIROU                 1                   1   \n",
       "3  50609050370   SIA ZI YUE                 1                   1   \n",
       "4  50211010344    OI KAY YI                 1                   1   \n",
       "\n",
       "   chinese_confidence  malay_scores  english_scores  chinese_scores  \\\n",
       "0                   0           5.0             5.0             0.0   \n",
       "1                   1           7.0             6.0             7.0   \n",
       "2                   1           6.5             5.5             6.5   \n",
       "3                   1           7.0             8.0             5.0   \n",
       "4                   1           6.0             9.0             7.5   \n",
       "\n",
       "                                     malay_narrative  \\\n",
       "0  Total Score: 5.0 out of 10 questions. Mismatch...   \n",
       "1  Total Score: 7.0 out of 10 questions. Mismatch...   \n",
       "2  Total Score: 6.5 out of 10 questions. Mismatch...   \n",
       "3  Total Score: 7.0 out of 10 questions. Mismatch...   \n",
       "4  Total Score: 6.0 out of 10 questions. Mismatch...   \n",
       "\n",
       "                                   english_narrative  \\\n",
       "0  Total Score: 5.0 out of 10 questions. Mismatch...   \n",
       "1  Total Score: 6.0 out of 10 questions. Mismatch...   \n",
       "2  Total Score: 5.5 out of 10 questions. Mismatch...   \n",
       "3  Total Score: 8.0 out of 10 questions. Mismatch...   \n",
       "4  Total Score: 9.0 out of 10 questions. (All Per...   \n",
       "\n",
       "                                   chinese_narrative  \n",
       "0  Total Score: 0.0 out of 10 questions. (All Per...  \n",
       "1  Total Score: 7.0 out of 10 questions. Mismatch...  \n",
       "2  Total Score: 6.5 out of 10 questions. Mismatch...  \n",
       "3  Total Score: 5.0 out of 10 questions. Mismatch...  \n",
       "4  Total Score: 7.5 out of 10 questions. Mismatch...  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- Core Scoring Functions ---\n",
    "\n",
    "def clean_answer(ans):\n",
    "    \"\"\"\n",
    "    Standardizes the answer string to 'PASS' or 'FAIL' if found, \n",
    "    otherwise returns None (for NaN/missing/unmatched strings).\n",
    "    \"\"\"\n",
    "    if pd.isna(ans) or ans is None:\n",
    "        return None\n",
    "    \n",
    "    ans_str = str(ans).upper().strip()\n",
    "    \n",
    "    if re.search(r'PASS', ans_str):\n",
    "        return 'PASS'\n",
    "    elif re.search(r'FAIL', ans_str):\n",
    "        return 'FAIL'\n",
    "        \n",
    "    return None\n",
    "\n",
    "def score_match(response_ans, key_ans):\n",
    "    \"\"\"\n",
    "    Applies the custom scoring logic for a single question response:\n",
    "    1. key=FAIL and response=PASS => 0.0\n",
    "    2. key=PASS and response=FAIL => 0.5\n",
    "    3. Matched => 1.0\n",
    "    4. NaN in key or response => NaN\n",
    "    \"\"\"\n",
    "    clean_response = clean_answer(response_ans)\n",
    "    clean_key = clean_answer(key_ans)\n",
    "\n",
    "    # Rule 4: Cannot score if either is missing or unreadable\n",
    "    if clean_response is None or clean_key is None:\n",
    "        return np.nan \n",
    "\n",
    "    # Rule 3: Perfect match\n",
    "    if clean_key == clean_response:\n",
    "        return 1.0 \n",
    "    \n",
    "    # Mismatched Cases\n",
    "    if clean_key == 'FAIL' and clean_response == 'PASS':\n",
    "        # Rule 1: Key says FAIL, Response says PASS => 0.0\n",
    "        return 0.0\n",
    "    elif clean_key == 'PASS' and clean_response == 'FAIL':\n",
    "        # Rule 2: Key says PASS, Response says FAIL => 0.5\n",
    "        return 0.5\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "# --- Narrative Summary Function (Revised for Integration) ---\n",
    "\n",
    "def generate_narrative_summary(responses_df, answer_key_df):\n",
    "    \"\"\"\n",
    "    Creates a multi-line narrative summary of scoring mismatches for each respondent.\n",
    "    This function MODIFIES responses_df by adding the narrative columns.\n",
    "    \"\"\"\n",
    "    languages = ['malay', 'english', 'chinese']\n",
    "    \n",
    "    # 1. Prepare Answer Key Lookup (Map question_key to original answer)\n",
    "    key_map = answer_key_df.set_index('question_key')['answer'].to_dict()\n",
    "    \n",
    "    # 2. Iterate row-by-row (per respondent) to build the narrative\n",
    "    # Use .apply() for better performance than iterrows()\n",
    "    \n",
    "    def create_narrative(row, lang):\n",
    "        lang_narrative_list = []\n",
    "        \n",
    "        # Get score columns for the specific language (e.g., 'malay_q1_prompt_status_score')\n",
    "        q_score_cols = [col for col in row.index if col.startswith(f'{lang}_') and col.endswith('_score')]\n",
    "        \n",
    "        lang_total_score = row.get(f'{lang}_scores', 0.0) # Get the final calculated score\n",
    "        \n",
    "        # Check for any scored questions\n",
    "        if not q_score_cols:\n",
    "             return f\"Total Score: 0.0. No scorable questions for {lang}.\"\n",
    "\n",
    "        # Iterate over the individual question scores\n",
    "        for score_col in q_score_cols:\n",
    "            score = row.get(score_col)\n",
    "            \n",
    "            # Only focus on partial (0.5) or zero (0.0) scores\n",
    "            if score == 0.5 or score == 0.0:\n",
    "                question_key = score_col.replace('_score', '')\n",
    "                \n",
    "                # Look up the original key and response answers\n",
    "                key_ans = key_map.get(question_key, 'KEY_NOT_FOUND')\n",
    "                response_ans = row.get(question_key, 'RESPONSE_NOT_FOUND')\n",
    "                \n",
    "                # Clean answers for the explanation\n",
    "                clean_key = clean_answer(key_ans)\n",
    "                clean_response = clean_answer(response_ans)\n",
    "\n",
    "                # Construct the detailed explanation\n",
    "                explanation = f\"Key: {clean_key} (Original: '{key_ans}'), Response: {clean_response} (Original: '{response_ans}')\"\n",
    "                \n",
    "                lang_narrative_list.append(\n",
    "                    f\"{question_key} => Score: {score} => Mismatch: {explanation}\"\n",
    "                )\n",
    "\n",
    "        # 3. Compile the final narrative for the language\n",
    "        if lang_narrative_list:\n",
    "            header = f\"Total Score: {lang_total_score} out of {len(q_score_cols)} questions. Mismatches ({len(lang_narrative_list)}):\"\n",
    "            return header + \"\\n\" + \"\\n\".join(lang_narrative_list)\n",
    "        else:\n",
    "            return f\"Total Score: {lang_total_score} out of {len(q_score_cols)} questions. (All Perfect Matches - Score 1.0)\"\n",
    "\n",
    "\n",
    "    # 4. Apply the narrative creation function to each row\n",
    "    for lang in languages:\n",
    "        responses_df[f'{lang}_narrative'] = responses_df.apply(\n",
    "            lambda row: create_narrative(row, lang), axis=1\n",
    "        )\n",
    "        \n",
    "    # Return the columns with the final narratives\n",
    "    return responses_df[['ic_number', 'name', 'malay_narrative', 'english_narrative', 'chinese_narrative']]\n",
    "\n",
    "\n",
    "# --- Main Score Calculation Function ---\n",
    "\n",
    "def calculate_all_scores(responses_df, answer_key_df):\n",
    "    \"\"\"Calculates individual question scores, sums them, and generates the narrative summary.\"\"\"\n",
    "    \n",
    "    # 1. Prepare Answer Key for Scoring\n",
    "    answer_key_df['clean_answer'] = answer_key_df['answer'].apply(clean_answer)\n",
    "\n",
    "    # 2. Calculate Individual Question Scores\n",
    "    for _, row in answer_key_df.iterrows():\n",
    "        q_key = row['question_key']\n",
    "        clean_key = row['clean_answer']\n",
    "        \n",
    "        if q_key in responses_df.columns:\n",
    "            score_col_name = f\"{q_key}_score\"\n",
    "            responses_df[score_col_name] = responses_df[q_key].apply(\n",
    "                lambda resp_ans: score_match(resp_ans, clean_key)\n",
    "            )\n",
    "\n",
    "    # 3. Calculate Total Language Scores\n",
    "    lang_prefixes = ['malay_', 'english_', 'chinese_']\n",
    "    final_score_cols = []\n",
    "    \n",
    "    for prefix in lang_prefixes:\n",
    "        all_score_cols = [col for col in responses_df.columns if col.endswith('_score')]\n",
    "        lang_score_cols = [col for col in all_score_cols if col.startswith(prefix)]\n",
    "        new_score_col_name = f'{prefix}scores'\n",
    "        \n",
    "        if lang_score_cols:\n",
    "            responses_df[new_score_col_name] = responses_df[lang_score_cols].sum(axis=1)\n",
    "        else:\n",
    "            responses_df[new_score_col_name] = 0.0 \n",
    "            \n",
    "        final_score_cols.append(new_score_col_name)\n",
    "\n",
    "    # 4. Generate Narrative Summary (The New Step)\n",
    "    narrative_df = generate_narrative_summary(responses_df, answer_key_df)\n",
    "\n",
    "    # 5. Combine and Return Final Output\n",
    "    # Merge the total scores and confidence columns with the new narrative columns\n",
    "    output_df = responses_df[[\n",
    "        'ic_number', 'name', \n",
    "        'malay_confidence', 'english_confidence', 'chinese_confidence'\n",
    "    ] + final_score_cols].merge(\n",
    "        narrative_df, on=['ic_number', 'name'], how='left'\n",
    "    )\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# FINAL STEP: You need to replace this block with your actual loaded DataFrames:\n",
    "# # Assuming you have loaded your data like this:\n",
    "responses_df = responses3 \n",
    "answer_key_df = answer_key\n",
    "\n",
    "final_output_df = calculate_all_scores(responses_df, answer_key_df)\n",
    "final_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d2112c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df.to_csv(r'C:\\Users\\jiayue.tan\\OneDrive - YTL\\Workstation\\dev\\annotator-assessment-profiler\\output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
